import os
import numpy as np
import pandas as pd
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))
from datacollapse.datacollapse import fit_data_collapse, fit_data_collapse_fse, collapse_transform

def debug_nu_inverse_problem():
    """è°ƒè¯•Î½^(-1)æ€»æ˜¯å°äº1çš„é—®é¢˜"""
    
    print("=== è°ƒè¯•Î½^(-1) < 1é—®é¢˜ ===")
    print("ç›®æ ‡ï¼šæ‰¾å‡ºä¸ºä»€ä¹ˆæˆ‘ä»¬æ€»æ˜¯å¾—åˆ°Î½^(-1) < 1ï¼Œè€ŒChatGPTå¾—åˆ°Î½^(-1) > 1")
    print("")
    
    # åŠ è½½æ•°æ®
    df_full = pd.read_csv(os.path.join(os.path.dirname(__file__), "real_data_combined.csv"))
    
    print(f"æ•°æ®æ£€æŸ¥:")
    print(f"  æ€»æ•°æ®ç‚¹: {len(df_full)}")
    print(f"  Lå€¼: {sorted(df_full['L'].unique())}")
    print(f"  UèŒƒå›´: {df_full['U'].min():.3f} - {df_full['U'].max():.3f}")
    print(f"  YèŒƒå›´: {df_full['Y'].min():.3f} - {df_full['Y'].max():.3f}")
    
    # 1. æ£€æŸ¥æ•°æ®æ ¼å¼å’Œå•ä½
    print(f"\n1. æ•°æ®æ ¼å¼æ£€æŸ¥:")
    print(f"å‰5è¡Œæ•°æ®:")
    print(df_full.head())
    
    # 2. æ£€æŸ¥æ‹Ÿåˆå‡½æ•°çš„ä½¿ç”¨æ–¹å¼
    print(f"\n2. æ‹Ÿåˆå‡½æ•°æµ‹è¯•:")
    
    # å‡†å¤‡Drop L=7æ•°æ®ï¼ˆChatGPTè¯´è¿™ä¸ªç»™å‡ºæœ€å¥½ç»“æœï¼‰
    df_drop_l7 = df_full[df_full["L"] != 7].copy().reset_index(drop=True)
    data_drop_l7 = df_drop_l7[["L","U","Y"]].to_numpy(float)
    err_drop_l7 = df_drop_l7["sigma"].to_numpy(float)
    
    print(f"Drop L=7æ•°æ®: {len(df_drop_l7)}ç‚¹, L={sorted(df_drop_l7['L'].unique())}")
    
    # 3. æµ‹è¯•ä¸åŒçš„å‚æ•°ç†è§£
    print(f"\n3. å‚æ•°å«ä¹‰æ£€æŸ¥:")
    print(f"fit_data_collapse(data, err, Uc0, a0, ...)")
    print(f"å…¶ä¸­a0æ˜¯ä»€ä¹ˆï¼Ÿ")
    print(f"- æˆ‘ç†è§£çš„: a0 = Î½^(-1) = 1/Î½")
    print(f"- æ ‡åº¦å…³ç³»: x = (U - Uc) * L^a")
    print(f"- å¦‚æœa = 1/Î½ï¼Œé‚£ä¹ˆa > 1æ„å‘³ç€Î½ < 1")
    print(f"- å¦‚æœa = Î½ï¼Œé‚£ä¹ˆa > 1æ„å‘³ç€Î½ > 1")
    print(f"")
    print(f"ğŸ¤” é—®é¢˜å¯èƒ½åœ¨äºå‚æ•°å®šä¹‰çš„æ··æ·†!")
    
    # 4. ç³»ç»Ÿæµ‹è¯•ä¸åŒçš„èµ·å§‹å‚æ•°èŒƒå›´
    print(f"\n4. ç³»ç»Ÿæµ‹è¯•ä¸åŒèµ·å§‹å‚æ•°:")
    
    test_cases = [
        # (Uc0, a0, description, expectation)
        (8.67, 0.5, "ä½aå€¼1", "å¦‚æœa=1/Î½ï¼Œåˆ™Î½=2"),
        (8.67, 0.8, "ä½aå€¼2", "å¦‚æœa=1/Î½ï¼Œåˆ™Î½=1.25"),
        (8.67, 1.0, "a=1", "å¦‚æœa=1/Î½ï¼Œåˆ™Î½=1"),
        (8.67, 1.2, "é«˜aå€¼1", "å¦‚æœa=1/Î½ï¼Œåˆ™Î½=0.83"),
        (8.67, 1.5, "é«˜aå€¼2", "å¦‚æœa=1/Î½ï¼Œåˆ™Î½=0.67"),
        (8.67, 2.0, "å¾ˆé«˜aå€¼", "å¦‚æœa=1/Î½ï¼Œåˆ™Î½=0.5"),
    ]
    
    results = []
    
    for Uc0, a0, desc, expect in test_cases:
        print(f"\n  æµ‹è¯• {desc}: Uc0={Uc0:.2f}, a0={a0:.1f}")
        print(f"    é¢„æœŸ: {expect}")
        
        try:
            # è®¾ç½®å®½æ¾è¾¹ç•Œæ¥çœ‹å‚æ•°çš„è‡ªç„¶æ”¶æ•›
            bounds = ((8.0, 9.0), (0.3, 3.0))
            
            (params, errs) = fit_data_collapse(data_drop_l7, err_drop_l7, 
                                             Uc0, a0, 
                                             n_knots=10, lam=1e-3, n_boot=3,
                                             bounds=bounds)
            
            # è®¡ç®—åç¼©è´¨é‡
            x_collapsed, Y_collapsed = collapse_transform(data_drop_l7, params)
            x_range = x_collapsed.max() - x_collapsed.min()
            y_ranges = []
            for L in sorted(df_drop_l7["L"].unique()):
                m = (df_drop_l7["L"]==L).to_numpy()
                y_range = Y_collapsed[m].max() - Y_collapsed[m].min()
                y_ranges.append(y_range)
            collapse_quality = x_range / np.mean(y_ranges)
            
            print(f"    ç»“æœ: U_c={params[0]:.4f}Â±{errs[0]:.4f}, a={params[1]:.4f}Â±{errs[1]:.4f}")
            print(f"    å¦‚æœa=1/Î½: Î½={1/params[1]:.4f}")
            print(f"    å¦‚æœa=Î½: Î½={params[1]:.4f}")
            print(f"    åç¼©è´¨é‡: {collapse_quality:.2f}")
            
            results.append({
                'desc': desc,
                'start_a': a0,
                'final_a': params[1],
                'final_Uc': params[0],
                'quality': collapse_quality,
                'nu_if_a_is_inv_nu': 1/params[1],
                'nu_if_a_is_nu': params[1]
            })
            
        except Exception as e:
            print(f"    å¤±è´¥: {e}")
    
    # 5. åˆ†æç»“æœæ¨¡å¼
    if results:
        print(f"\n5. ç»“æœæ¨¡å¼åˆ†æ:")
        print(f"{'èµ·å§‹a':<8} {'æœ€ç»ˆa':<8} {'Î½(a=1/Î½)':<12} {'Î½(a=Î½)':<10} {'è´¨é‡':<8}")
        print("-" * 60)
        
        for r in results:
            print(f"{r['start_a']:<8.1f} {r['final_a']:<8.4f} {r['nu_if_a_is_inv_nu']:<12.4f} {r['nu_if_a_is_nu']:<10.4f} {r['quality']:<8.1f}")
        
        # æ‰¾åˆ°è´¨é‡æœ€é«˜çš„ç»“æœ
        best = max(results, key=lambda x: x['quality'])
        print(f"\nğŸ† æœ€ä½³è´¨é‡ç»“æœ: {best['desc']}")
        print(f"   æœ€ç»ˆå‚æ•°: U_c={best['final_Uc']:.4f}, a={best['final_a']:.4f}")
        print(f"   å¦‚æœa=1/Î½: Î½={best['nu_if_a_is_inv_nu']:.4f}")
        print(f"   å¦‚æœa=Î½: Î½={best['nu_if_a_is_nu']:.4f}")
        print(f"   åç¼©è´¨é‡: {best['quality']:.2f}")
        
        # ä¸ChatGPTå¯¹æ¯”
        chatgpt_a = 1.056  # ChatGPTçš„Î½^(-1)
        print(f"\nğŸ” ä¸ChatGPTå¯¹æ¯”:")
        print(f"   ChatGPT: Î½^(-1)=1.056 â†’ Î½=0.947")
        print(f"   å¦‚æœæˆ‘ä»¬çš„a=Î½^(-1): æœ€ä½³a={best['final_a']:.3f} â†’ Î½={1/best['final_a']:.3f}")
        print(f"   å¦‚æœæˆ‘ä»¬çš„a=Î½: æœ€ä½³a={best['final_a']:.3f} â†’ Î½={best['final_a']:.3f}")
        
        if abs(best['final_a'] - chatgpt_a) < 0.1:
            print(f"   âœ… æˆ‘ä»¬çš„aæ¥è¿‘ChatGPTçš„Î½^(-1)ï¼Œå‚æ•°å®šä¹‰ä¸€è‡´")
        elif abs(1/best['final_a'] - 1/chatgpt_a) < 0.1:
            print(f"   âœ… æˆ‘ä»¬çš„1/aæ¥è¿‘ChatGPTçš„Î½ï¼Œå‚æ•°å®šä¹‰ç›¸å")
        else:
            print(f"   âŒ å‚æ•°ä¸åŒ¹é…ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥")
    
    return results

def check_scaling_relationship():
    """æ£€æŸ¥æ ‡åº¦å…³ç³»çš„å®šä¹‰"""
    
    print(f"\n" + "="*60)
    print(f"=== æ£€æŸ¥æ ‡åº¦å…³ç³»å®šä¹‰ ===")
    
    print(f"æ ‡å‡†æœ‰é™å°ºå¯¸æ ‡åº¦ç†è®º:")
    print(f"Y(U,L) = L^(d-z) * F((U-Uc)*L^(1/Î½))")
    print(f"")
    print(f"ç®€åŒ–çš„æ•°æ®åç¼©å½¢å¼:")
    print(f"Y â‰ˆ f(x)ï¼Œå…¶ä¸­ x = (U - Uc) * L^a")
    print(f"")
    print(f"å…³é”®é—®é¢˜: açš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ")
    print(f"é€‰é¡¹1: a = 1/Î½  (æˆ‘ä¸€ç›´å‡è®¾çš„)")
    print(f"é€‰é¡¹2: a = Î½    (ChatGPTå¯èƒ½å‡è®¾çš„)")
    print(f"")
    
    # åŠ è½½æ•°æ®åšä¸€ä¸ªç›´è§‚æ£€æŸ¥
    df_full = pd.read_csv(os.path.join(os.path.dirname(__file__), "real_data_combined.csv"))
    df_drop_l7 = df_full[df_full["L"] != 7].copy().reset_index(drop=True)
    
    print(f"ç›´è§‚æ£€æŸ¥ - çœ‹çœ‹å“ªä¸ªå®šä¹‰æ›´åˆç†:")
    
    # ä½¿ç”¨ChatGPTçš„å‚æ•°
    Uc_chatgpt = 8.670
    a_chatgpt = 1.056  # ChatGPTè¯´è¿™æ˜¯Î½^(-1)
    
    print(f"ChatGPTå‚æ•°: Uc={Uc_chatgpt}, Î½^(-1)={a_chatgpt}")
    print(f"")
    
    # è®¡ç®—ä¸¤ç§ç†è§£ä¸‹çš„åç¼©åæ ‡
    for L in sorted(df_drop_l7["L"].unique()):
        L_data = df_drop_l7[df_drop_l7["L"] == L]
        U_vals = L_data["U"].values
        Y_vals = L_data["Y"].values
        
        # å‡è®¾a = 1/Î½
        x1 = (U_vals - Uc_chatgpt) * (L ** a_chatgpt)
        
        # å‡è®¾a = Î½  
        x2 = (U_vals - Uc_chatgpt) * (L ** (1/a_chatgpt))
        
        print(f"L={L}:")
        print(f"  å¦‚æœa=1/Î½: xèŒƒå›´ = [{x1.min():.2f}, {x1.max():.2f}]")
        print(f"  å¦‚æœa=Î½:   xèŒƒå›´ = [{x2.min():.2f}, {x2.max():.2f}]")
    
    print(f"\nğŸ’¡ è§‚å¯Ÿ: å¦‚æœä¸åŒLçš„xèŒƒå›´é‡å è‰¯å¥½ï¼Œè¯´æ˜å®šä¹‰æ­£ç¡®")

def main():
    print("ğŸ” è°ƒè¯•Î½^(-1) < 1çš„ç³»ç»Ÿæ€§é—®é¢˜")
    print("="*60)
    
    # è°ƒè¯•å‚æ•°é—®é¢˜
    results = debug_nu_inverse_problem()
    
    # æ£€æŸ¥æ ‡åº¦å…³ç³»å®šä¹‰
    check_scaling_relationship()
    
    print(f"\nğŸ“‹ è¯Šæ–­æ€»ç»“:")
    print(f"1. æ£€æŸ¥äº†æ•°æ®æ ¼å¼å’ŒèŒƒå›´")
    print(f"2. ç³»ç»Ÿæµ‹è¯•äº†ä¸åŒèµ·å§‹å‚æ•°")
    print(f"3. åˆ†æäº†å‚æ•°å®šä¹‰çš„å¯èƒ½æ··æ·†")
    print(f"4. ä¸ChatGPTç»“æœè¿›è¡Œäº†å¯¹æ¯”")
    
    if results:
        best = max(results, key=lambda x: x['quality'])
        print(f"\nğŸ¯ å»ºè®®:")
        print(f"æœ€ä½³æ‹Ÿåˆå‚æ•°: a={best['final_a']:.4f}")
        print(f"éœ€è¦æ˜ç¡®açš„ç‰©ç†æ„ä¹‰æ¥ä¸ChatGPTå¯¹æ¯”")

if __name__ == "__main__":
    main() 